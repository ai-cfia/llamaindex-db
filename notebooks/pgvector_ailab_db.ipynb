{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bccd47fc",
      "metadata": {
        "id": "bccd47fc"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/vector_stores/postgres.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db0855d0",
      "metadata": {
        "id": "db0855d0"
      },
      "source": [
        "# Postgres Vector Store\n",
        "\n",
        "This notebook shows how we can create a llI seeamaindex in PostgresSQL (PGVector) as opposed to in-memory, from data that has already been prepared for indexing (chunking, embeddings generations...) in `ailab-db`.\n",
        "\n",
        "Testings on our azure pg show a disappointing `25 seconds` delay vs `<0.5 seconds` on local pg. It is worth investigating the configuration differences between the local pg and the azure one that could cause such a drastic jump.\n",
        "\n",
        "We noticed that on either db, no index is actually created on the embedding column of the vector store table (`data_llamaindex`). And looking closely in the llamaindex codebase, there is no obvious mention of it's creation. So we created one manually using:\n",
        "\n",
        "`CREATE INDEX ON data_llamaindex USING hnsw (embedding vector_cosine_ops);`\n",
        "\n",
        "The delay is now `1.13 seconds` with hnsw index vs `25 seconds` without.\n",
        "\n",
        "This is a huge improvement. We should also consider that our current azure pg instance is a development one, less powerful than the one meant for production.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2fc9c18",
      "metadata": {
        "id": "d2fc9c18"
      },
      "outputs": [],
      "source": [
        "# %pip install -r ../../requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c2d1c538",
      "metadata": {
        "id": "c2d1c538"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import logging\n",
        "import sys\n",
        "from llama_index.core import StorageContext\n",
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_index.vector_stores.postgres import PGVectorStore\n",
        "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
        "from llama_index.llms.azure_openai import AzureOpenAI\n",
        "from llama_index.core import Settings\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from llama_index.storage.index_store.postgres import PostgresIndexStore\n",
        "from llama_index.storage.docstore.postgres import PostgresDocumentStore\n",
        "import psycopg\n",
        "from psycopg.sql import SQL, Identifier\n",
        "from psycopg.rows import dict_row\n",
        "import json\n",
        "import pickle\n",
        "from sqlalchemy import make_url\n",
        "from llama_index.core.schema import TextNode\n",
        "from tqdm import tqdm\n",
        "from llama_index.readers.web import SimpleWebPageReader\n",
        "from llama_index.core.extractors import QuestionsAnsweredExtractor\n",
        "import random\n",
        "from pprint import pprint\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Uncomment to see debug logs\n",
        "# logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
        "# logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "7ef96d95",
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_to_pickle(data, filename):\n",
        "    with open(filename, \"wb\") as file:\n",
        "        pickle.dump(data, file)\n",
        "\n",
        "\n",
        "def load_from_pickle(filename):\n",
        "    with open(filename, \"rb\") as file:\n",
        "        return pickle.load(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26c71b6d",
      "metadata": {
        "id": "26c71b6d"
      },
      "source": [
        "### Setup LLM and Embed Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "67b86621",
      "metadata": {
        "id": "67b86621"
      },
      "outputs": [],
      "source": [
        "llm = AzureOpenAI(\n",
        "    model=\"gpt-4\",\n",
        "    deployment_name=\"ailab-llm\",\n",
        "    api_key=os.getenv(\"API_KEY\"),\n",
        "    azure_endpoint=os.getenv(\"AZURE_ENDPOINT\"),\n",
        "    api_version=os.getenv(\"API_VERSION\"),\n",
        ")\n",
        "\n",
        "embed_model = AzureOpenAIEmbedding(\n",
        "    model=\"text-embedding-ada-002\",\n",
        "    deployment_name=\"ada\",\n",
        "    api_key=os.getenv(\"API_KEY\"),\n",
        "    azure_endpoint=os.getenv(\"AZURE_ENDPOINT\"),\n",
        "    api_version=os.getenv(\"API_VERSION\"),\n",
        ")\n",
        "\n",
        "Settings.llm = llm\n",
        "Settings.embed_model = embed_model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45551f5d",
      "metadata": {},
      "source": [
        "### Creating nodes from louis_v005.documents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "05dd4f72",
      "metadata": {},
      "outputs": [],
      "source": [
        "louis_db = os.getenv(\"DB_NAME\")\n",
        "host = os.getenv(\"DB_HOST\")\n",
        "password = os.getenv(\"DB_PASSWORD\")\n",
        "port = os.getenv(\"DB_PORT\")\n",
        "user = os.getenv(\"DB_USER\")\n",
        "llamaindex_db = \"llamaindex_db_legacy\"\n",
        "admin_db = \"postgres\"\n",
        "llamaindex_schema = \"v_0_0_1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "2b126c54",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing records: 100%|██████████| 103836/103836 [01:03<00:00, 1644.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Node ID: a8fa477f-5a9e-493a-b50a-e435a15b1bc5\n",
            "Text: 6.18 Enzymes Reserved for future use 6.19 Gut modifier\n",
            "ingredients 6.19.1 Prebiotics 6.19.2 Viable microorganisms 6.19.3\n",
            "Acidifiers 6.19.1 Prebiotics Reserved for future use 6.19.2 Viable\n",
            "microorganisms Reserved for future use 6.19.3 Acidifiers Reserved for\n",
            "future use 6.20 Forage additives 1-601-019 Propionic acid Is an\n",
            "organic acid, generally e...\n"
          ]
        }
      ],
      "source": [
        "conn_string = (\n",
        "    f\"dbname={louis_db} \"\n",
        "    f\"user={user} \"\n",
        "    f\"password={password} \"\n",
        "    f\"host={host} \"\n",
        "    f\"port={port}\"\n",
        ")\n",
        "\n",
        "query = \"\"\"\n",
        "    SELECT id, content, embedding, chunk_id, url, title, subtitle, tokens_count, last_updated, score\n",
        "    FROM louis_v005.documents\n",
        "\"\"\"\n",
        "nodes = []\n",
        "with psycopg.connect(conn_string) as conn:\n",
        "    with conn.cursor(row_factory=dict_row) as cur:\n",
        "        results = cur.execute(query).fetchall()\n",
        "        for r in tqdm(results, desc=\"Processing records\"):\n",
        "            node = TextNode(\n",
        "                text=r[\"content\"],\n",
        "                id_=str(r[\"chunk_id\"]),\n",
        "                embedding=json.loads(r[\"embedding\"]),\n",
        "            )\n",
        "            node.metadata = {\n",
        "                \"id\": str(r[\"id\"]),\n",
        "                \"chunk_id\": str(r[\"chunk_id\"]),\n",
        "                \"url\": r[\"url\"],\n",
        "                \"title\": r[\"title\"],\n",
        "                \"subtitle\": r[\"subtitle\"],\n",
        "                \"tokens_count\": r[\"tokens_count\"],\n",
        "                \"last_updated\": (r[\"last_updated\"]),\n",
        "                \"score\": r[\"score\"],\n",
        "            }\n",
        "            nodes.append(node)\n",
        "\n",
        "print(nodes[0])\n",
        "save_to_pickle(nodes, \"nodes.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bd24f0a",
      "metadata": {
        "id": "7bd24f0a"
      },
      "source": [
        "### Create the Database\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e6d61e73",
      "metadata": {
        "id": "e6d61e73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Database llamaindex_db_legacy already exists.\n"
          ]
        }
      ],
      "source": [
        "connection_string = (\n",
        "    f\"dbname={admin_db} \"\n",
        "    f\"user={user} \"\n",
        "    f\"password={password} \"\n",
        "    f\"host={host} \"\n",
        "    f\"port={port}\"\n",
        ")\n",
        "# connection_string = \"postgresql://postgres:testpwd@localhost:5432\"\n",
        "\n",
        "# with psycopg.connect(connection_string) as conn:\n",
        "#     conn.autocommit = True\n",
        "#     with conn.cursor() as cur:\n",
        "#         cur.execute(f\"DROP DATABASE IF EXISTS {llama_database}\")\n",
        "#         cur.execute(f\"CREATE DATABASE {llama_database}\")\n",
        "\n",
        "try:\n",
        "    with psycopg.connect(connection_string) as conn:\n",
        "        conn.autocommit = True\n",
        "        with conn.cursor() as cur:\n",
        "            cur.execute(f\"CREATE DATABASE {llamaindex_db}\")\n",
        "            print(f\"Database {llamaindex_db} created.\")\n",
        "except psycopg.errors.DuplicateDatabase:\n",
        "    print(f\"Database {llamaindex_db} already exists.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0232fd1",
      "metadata": {
        "id": "c0232fd1"
      },
      "source": [
        "### Create the tables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8731da62",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "55d642be4afd424dbeddcc98a6313baa",
            "4bedc19d901346dbafbeff1d25638562"
          ]
        },
        "id": "8731da62",
        "outputId": "bc5f1134-e829-4357-9caa-f3012cc011be"
      },
      "outputs": [],
      "source": [
        "vector_store = PGVectorStore.from_params(\n",
        "    database=llamaindex_db,\n",
        "    host=host,\n",
        "    password=password,\n",
        "    port=port,\n",
        "    user=user,\n",
        "    embed_dim=1536,\n",
        "    schema_name=llamaindex_schema,\n",
        ")\n",
        "\n",
        "document_store = PostgresDocumentStore.from_params(\n",
        "    database=llamaindex_db,\n",
        "    host=host,\n",
        "    password=password,\n",
        "    port=port,\n",
        "    user=user,\n",
        "    schema_name=llamaindex_schema,\n",
        ")\n",
        "\n",
        "index_store = PostgresIndexStore.from_params(\n",
        "    database=llamaindex_db,\n",
        "    host=host,\n",
        "    password=password,\n",
        "    port=port,\n",
        "    user=user,\n",
        "    schema_name=llamaindex_schema,\n",
        ")\n",
        "\n",
        "storage_context = StorageContext.from_defaults(\n",
        "    docstore=document_store,\n",
        "    index_store=index_store,\n",
        "    vector_store=vector_store,\n",
        ")\n",
        "\n",
        "storage_context.docstore.add_documents(nodes)\n",
        "\n",
        "index = VectorStoreIndex(nodes, storage_context=storage_context)\n",
        "\n",
        "retriever = index.as_retriever(similarity_top_k=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c4c592a",
      "metadata": {},
      "source": [
        "### Create the index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9180ded8",
      "metadata": {},
      "outputs": [],
      "source": [
        "connection_string = (\n",
        "    f\"dbname={llamaindex_db} \"\n",
        "    f\"user={user} \"\n",
        "    f\"password={password} \"\n",
        "    f\"host={host} \"\n",
        "    f\"port={port}\"\n",
        ")\n",
        "\n",
        "schema = Identifier(llamaindex_schema)\n",
        "query = SQL(\n",
        "    \"CREATE INDEX ON {}.data_llamaindex USING hnsw (embedding vector_cosine_ops)\"\n",
        ").format(schema)\n",
        "\n",
        "with psycopg.connect(connection_string) as conn:\n",
        "    conn.autocommit = True\n",
        "    with conn.cursor() as cur:\n",
        "        cur.execute(query)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54ef35ab",
      "metadata": {},
      "source": [
        "### Testing\n",
        "\n",
        "#### Generating a question from a random url\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "c49814dc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['https://inspection.canada.ca/preventive-controls/sampling-procedures/eng/1518033335104/1528203403149',\n",
            " 'https://inspection.canada.ca/eng/1664715510668/1664715511012',\n",
            " 'https://inspection.canada.ca/plant-health/potatoes/potato-varieties/norland/eng/1312587385821/1312587385822',\n",
            " 'https://inspection.canada.ca/eng/1653077788730/1653077789089',\n",
            " 'https://inspection.canada.ca/plant-health/potatoes/references/eng/1326492425237/1326492502093']\n"
          ]
        }
      ],
      "source": [
        "query = \"\"\"\n",
        "    SELECT c.url\n",
        "    FROM louis_v005.crawl as c\n",
        "    \"\"\"\n",
        "with psycopg.connect(conn_string) as conn:\n",
        "    with conn.cursor() as cur:\n",
        "        results = cur.execute(query).fetchall()\n",
        "        urls = [r[0] for r in results]\n",
        "\n",
        "urls = [url for url in urls if \"/fra/\" not in url]\n",
        "pprint(urls[0:5])\n",
        "save_to_pickle(urls, \"urls.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "0a2bcc07",
      "metadata": {
        "id": "0a2bcc07"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:02<00:00,  2.64s/it]\n"
          ]
        }
      ],
      "source": [
        "urls = load_from_pickle(\"urls.pkl\")\n",
        "# random_url = random.choice(urls)\n",
        "random_url = urls[0]\n",
        "documents = SimpleWebPageReader(html_to_text=True).load_data([random_url])\n",
        "assert len(documents) == 1\n",
        "extractor = QuestionsAnsweredExtractor(questions=1)\n",
        "questions = await extractor.aextract(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b280db13",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "url https://inspection.canada.ca/preventive-controls/sampling-procedures/eng/1518033335104/1528203403149\n",
            "What are the steps and considerations for collecting environmental samples for microbial testing in a food production setting, according to the Canadian Food Inspection Agency?\n"
          ]
        }
      ],
      "source": [
        "print(\"url\", random_url)\n",
        "question = questions[0][\"questions_this_excerpt_can_answer\"].removeprefix(\"Question: \")\n",
        "print(question)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e173a78",
      "metadata": {},
      "source": [
        "#### Checking if querying the index returns the right url\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "158034e3",
      "metadata": {},
      "outputs": [],
      "source": [
        "vector_store = PGVectorStore.from_params(\n",
        "    database=llamaindex_db,\n",
        "    host=host,\n",
        "    password=password,\n",
        "    port=port,\n",
        "    user=user,\n",
        "    embed_dim=1536,\n",
        "    schema_name=llamaindex_schema\n",
        ")\n",
        "\n",
        "index = VectorStoreIndex.from_vector_store(vector_store=vector_store)\n",
        "retriever = index.as_retriever(similarity_top_k=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "772f9ea7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# import time\n",
        "# start_time = time.time()\n",
        "nodes = retriever.retrieve(question)\n",
        "\n",
        "# end_time = time.time()\n",
        "# elapsed_time = end_time - start_time\n",
        "# print(f\"Elapsed time: {elapsed_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "77c4ed49",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'node': {'id_': 'e456dca5-3079-4702-b89c-d469f951526f', 'embedding': None, 'metadata': {'id': '379a866f-3802-485e-afe3-85bb4c08e238', 'chunk_id': 'e456dca5-3079-4702-b89c-d469f951526f', 'url': 'https://inspection.canada.ca/inspection-and-enforcement/guidance-for-food-inspection-activities/sample-collection/food-sample-collection/eng/1540234969218/1540235089869', 'title': 'Operational guideline: Food sample collection - Canadian Food Inspection Agency', 'subtitle': 'On this page;1.0 Purpose;2.0 Authorities', 'tokens_count': 482, 'last_updated': '2023-03-24', 'score': 0.5859392646494657}, 'excluded_embed_metadata_keys': [], 'excluded_llm_metadata_keys': [], 'relationships': {}, 'text': 'On this page 1.0 Purpose 2.0 Authorities 3.0 Reference documents 4.0 Definitions 5.0 Acronyms 6.0 Operational guideline 6.1 Prepare for the inspection 6.2 Conduct the inspection 6.3 Communicate the inspection results 6.4 Conduct the follow-up inspection 7.0 Appendix Appendix 1: Aseptic sample collection Appendix 2: Core drilling for food samples Appendix 3: Environmental sample collection Appendix 4: Random sample collection Appendix 5: Water and ice sample collection Appendix 6: Types of analyses for food samples Appendix 7: Canadian Shellfish Sanitation Program (CSSP) sample collection Appendix 8: Dairy products sample collection Appendix 9: Fish and seafood sample collection Appendix 10: Fresh fruit and vegetable sample collection Appendix 11: Honey sample collection Appendix 12: Maple sample collection Appendix 13: Meat and poultry products sample collection Appendix 14: Processed egg product sample collection Appendix 15: Processed fruit and vegetable products sample collection Appendix 16: Shell egg sample collection Appendix 17: CFIA payment for food sample collection\\n1.0 Purpose The purpose of this document is to provide guidance to Canadian Food Inspection Agency (CFIA) inspection staff on the general guidelines for food sample collection. Sample collection is a task conducted under the Standard Inspection Process (SIP) and used to assess compliance of a food with relevant legislation and to gather baseline information on food products. This guidance supports inspectors to take samples that are representative of the food and the food production environment and applies to samples taken to support planned, official and as required food sample collection activities. This guidance is written with the assumption that inspection staff have reviewed the Food inspection guidance: sample collection page (accessible only on the Government of Canada network) and have been properly trained in sample collection techniques. This document is intended to be used in conjunction with other guidance documents as referenced in Section 3.0.\\n2.0 Authorities Food and Drugs Act (FDA) Food and Drug Regulations (FDR) Health of Animals Act (HAA) Health of Animals Regulations (HAR) Safe Food for Canadians Act (SFCA) Safe Food for Canadians Regulations (SFCR) The inspection powers, control actions and enforcement actions authorized by the above legislation are identified and explained in the Operational guideline – Food regulatory response guidelines.', 'start_char_idx': None, 'end_char_idx': None, 'text_template': '{metadata_str}\\n\\n{content}', 'metadata_template': '{key}: {value}', 'metadata_seperator': '\\n', 'class_name': 'TextNode'}, 'score': 0.8956051406625395, 'class_name': 'NodeWithScore'}\n"
          ]
        }
      ],
      "source": [
        "print(nodes[0].dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "ec2a6918",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Position: 3 Sampling procedures - Canadian Food Inspection Agency\n"
          ]
        }
      ],
      "source": [
        "found = False\n",
        "for i, n in enumerate(nodes):\n",
        "    if n.metadata[\"url\"] == random_url:\n",
        "        found = True\n",
        "        print(f\"Position: {i+1}\", n.metadata[\"title\"])\n",
        "\n",
        "if not found:\n",
        "    print(\"Right:\", random_url)\n",
        "    for n in nodes:\n",
        "        print(\"Wrong: \", n.metadata[\"url\"])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
