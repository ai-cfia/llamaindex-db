{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bccd47fc",
      "metadata": {
        "id": "bccd47fc"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/vector_stores/postgres.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db0855d0",
      "metadata": {
        "id": "db0855d0"
      },
      "source": [
        "# Postgres Vector Store\n",
        "\n",
        "This notebook shows how we can create a llI seeamaindex in PostgresSQL (PGVector) as opposed to in-memory, from data that has already been prepared for indexing (chunking, embeddings generations...) in `ailab-db`. \n",
        "\n",
        "Testings on our azure pg show a disappointing `25 seconds` delay vs `<0.5 seconds` on local pg. It is worth investigating the configuration differences between the local pg and the azure one that could cause such a drastic jump.\n",
        "\n",
        "We noticed that on either db, no index is actually created on the embedding column of the vector store table (`data_llamaindex`). And looking closely in the llamaindex codebase, there is no obvious mention of it's creation. So we created one manually using:\n",
        "\n",
        "`CREATE INDEX ON data_llamaindex USING hnsw (embedding vector_cosine_ops);`\n",
        "\n",
        "The delay is now `1.13 seconds` with hnsw index vs `25 seconds` without.\n",
        "\n",
        "This is a huge improvement. We should also consider that our current azure pg instance is a development one, less powerful than the one meant for production.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2fc9c18",
      "metadata": {
        "id": "d2fc9c18"
      },
      "outputs": [],
      "source": [
        "# %pip install -r ../../requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c2d1c538",
      "metadata": {
        "id": "c2d1c538"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import logging\n",
        "import sys\n",
        "from llama_index.core import StorageContext\n",
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_index.vector_stores.postgres import PGVectorStore\n",
        "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
        "from llama_index.llms.azure_openai import AzureOpenAI\n",
        "from llama_index.core import Settings\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from llama_index.storage.index_store.postgres import PostgresIndexStore\n",
        "from llama_index.storage.docstore.postgres import PostgresDocumentStore\n",
        "import psycopg\n",
        "from psycopg.rows import dict_row\n",
        "import json\n",
        "import pickle\n",
        "from sqlalchemy import make_url\n",
        "from llama_index.core.schema import TextNode\n",
        "from tqdm import tqdm\n",
        "from llama_index.readers.web import SimpleWebPageReader\n",
        "from llama_index.core.extractors import QuestionsAnsweredExtractor\n",
        "import random\n",
        "from pprint import pprint\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Uncomment to see debug logs\n",
        "# logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
        "# logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "7ef96d95",
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_to_pickle(data, filename):\n",
        "    with open(filename, \"wb\") as file:\n",
        "        pickle.dump(data, file)\n",
        "\n",
        "def load_from_pickle(filename):\n",
        "    with open(filename, \"rb\") as file:\n",
        "        return pickle.load(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26c71b6d",
      "metadata": {
        "id": "26c71b6d"
      },
      "source": [
        "### Setup LLM and Embed Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "67b86621",
      "metadata": {
        "id": "67b86621"
      },
      "outputs": [],
      "source": [
        "llm = AzureOpenAI(\n",
        "    model=\"gpt-4\",\n",
        "    deployment_name=\"ailab-llm\",\n",
        "    api_key=os.getenv(\"API_KEY\"),\n",
        "    azure_endpoint=os.getenv(\"AZURE_ENDPOINT\"),\n",
        "    api_version=os.getenv(\"API_VERSION\"),\n",
        ")\n",
        "\n",
        "embed_model = AzureOpenAIEmbedding(\n",
        "    model=\"text-embedding-ada-002\",\n",
        "    deployment_name=\"ada\",\n",
        "    api_key=os.getenv(\"API_KEY\"),\n",
        "    azure_endpoint=os.getenv(\"AZURE_ENDPOINT\"),\n",
        "    api_version=os.getenv(\"API_VERSION\"),\n",
        ")\n",
        "\n",
        "Settings.llm = llm\n",
        "Settings.embed_model = embed_model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45551f5d",
      "metadata": {},
      "source": [
        "### Creating nodes from louis_v005.documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "05dd4f72",
      "metadata": {},
      "outputs": [],
      "source": [
        "database=os.getenv('DB_NAME')\n",
        "host=os.getenv('DB_HOST')\n",
        "password=os.getenv('DB_PASSWORD')\n",
        "port=os.getenv('DB_PORT')\n",
        "user=os.getenv('DB_USER')\n",
        "\n",
        "conn_string = (\n",
        "    f\"dbname={database} \"\n",
        "    f\"user={user} \"\n",
        "    f\"password={password} \"\n",
        "    f\"host={host} \"\n",
        "    f\"port={port}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2b126c54",
      "metadata": {},
      "outputs": [],
      "source": [
        "query = \"\"\"\n",
        "    SELECT id, content, embedding, chunk_id, url, title, subtitle, tokens_count, last_updated, score\n",
        "    FROM louis_v005.documents\n",
        "\"\"\"\n",
        "nodes = []\n",
        "with psycopg.connect(conn_string) as conn:\n",
        "    with conn.cursor(row_factory=dict_row) as cur:\n",
        "        results = cur.execute(query).fetchall()\n",
        "        for r in tqdm(results, desc=\"Processing records\"):\n",
        "            node = TextNode(\n",
        "                text=r[\"content\"],\n",
        "                id_=str(r[\"id\"]),\n",
        "                embedding=json.loads(r[\"embedding\"]),\n",
        "            )\n",
        "            node.metadata = {\n",
        "                \"id\": str(r[\"id\"]),\n",
        "                'chunk_id': str(r['chunk_id']),\n",
        "                'url': r['url'],\n",
        "                'title': r['title'],\n",
        "                'subtitle': r['subtitle'],\n",
        "                'tokens_count': r['tokens_count'],\n",
        "                'last_updated': (r['last_updated']),\n",
        "                'score': r['score']\n",
        "            }\n",
        "            nodes.append(node)\n",
        "\n",
        "print(nodes[0])\n",
        "save_to_pickle(nodes, \"nodes.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bd24f0a",
      "metadata": {
        "id": "7bd24f0a"
      },
      "source": [
        "### Create the Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "e6d61e73",
      "metadata": {
        "id": "e6d61e73"
      },
      "outputs": [],
      "source": [
        "connection_string=conn_string\n",
        "# connection_string = \"postgresql://postgres:testpwd@localhost:5432\"\n",
        "new_database = \"llamaindexdb\"\n",
        "\n",
        "with psycopg.connect(connection_string) as conn:\n",
        "    conn.autocommit = True\n",
        "    with conn.cursor() as cur:\n",
        "        cur.execute(f\"DROP DATABASE IF EXISTS {new_database}\")\n",
        "        cur.execute(f\"CREATE DATABASE {new_database}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0232fd1",
      "metadata": {
        "id": "c0232fd1"
      },
      "source": [
        "### Create the indexes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "8731da62",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "55d642be4afd424dbeddcc98a6313baa",
            "4bedc19d901346dbafbeff1d25638562"
          ]
        },
        "id": "8731da62",
        "outputId": "bc5f1134-e829-4357-9caa-f3012cc011be"
      },
      "outputs": [],
      "source": [
        "vector_store = PGVectorStore.from_params(\n",
        "    database=new_database,\n",
        "    host=host,\n",
        "    password=password,\n",
        "    port=port,\n",
        "    user=user,\n",
        "    embed_dim=1536,\n",
        ")\n",
        "\n",
        "document_store = PostgresDocumentStore.from_params(    \n",
        "    database=new_database,\n",
        "    host=host,\n",
        "    password=password,\n",
        "    port=port,\n",
        "    user=user,\n",
        ")\n",
        "\n",
        "index_store = PostgresIndexStore.from_params(\n",
        "    database=new_database,\n",
        "    host=host,\n",
        "    password=password,\n",
        "    port=port,\n",
        "    user=user,\n",
        ")\n",
        "\n",
        "storage_context = StorageContext.from_defaults(\n",
        "    docstore=document_store,\n",
        "    index_store=index_store, \n",
        "    vector_store=vector_store, \n",
        ")\n",
        "\n",
        "storage_context.docstore.add_documents(nodes)\n",
        "\n",
        "index = VectorStoreIndex(nodes, storage_context=storage_context)\n",
        "\n",
        "retriever = index.as_retriever(similarity_top_k=5)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9180ded8",
      "metadata": {},
      "outputs": [],
      "source": [
        "conn_string_new_db = (\n",
        "    f\"dbname={new_database} \"\n",
        "    f\"user={user} \"\n",
        "    f\"password={password} \"\n",
        "    f\"host={host} \"\n",
        "    f\"port={port}\"\n",
        ")\n",
        "\n",
        "with psycopg.connect(conn_string_new_db) as conn:\n",
        "    conn.autocommit = True\n",
        "    with conn.cursor() as cur:\n",
        "        cur.execute(\"\"\"\n",
        "        CREATE INDEX ON public.data_llamaindex USING hnsw (embedding vector_cosine_ops);\n",
        "        \"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54ef35ab",
      "metadata": {},
      "source": [
        "### Testing\n",
        "\n",
        "#### Generating a question from a random url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "c49814dc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['https://inspection.canada.ca/preventive-controls/sampling-procedures/eng/1518033335104/1528203403149',\n",
            " 'https://inspection.canada.ca/eng/1664715510668/1664715511012',\n",
            " 'https://inspection.canada.ca/plant-health/potatoes/potato-varieties/norland/eng/1312587385821/1312587385822',\n",
            " 'https://inspection.canada.ca/eng/1653077788730/1653077789089',\n",
            " 'https://inspection.canada.ca/plant-health/potatoes/references/eng/1326492425237/1326492502093']\n"
          ]
        }
      ],
      "source": [
        "query = \"\"\"\n",
        "    SELECT c.url\n",
        "    FROM louis_v005.crawl as c\n",
        "    \"\"\"\n",
        "with psycopg.connect(conn_string) as conn:\n",
        "    with conn.cursor() as cur:\n",
        "        results = cur.execute(query).fetchall()\n",
        "        urls = [r[0] for r in results]\n",
        "\n",
        "urls = [url for url in urls if \"/fra/\" not in url]\n",
        "pprint(urls[0:5])\n",
        "save_to_pickle(urls, \"urls.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0a2bcc07",
      "metadata": {
        "id": "0a2bcc07"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:08<00:00,  8.05s/it]\n"
          ]
        }
      ],
      "source": [
        "urls = load_from_pickle(\"urls.pkl\")\n",
        "# random_url = random.choice(urls)\n",
        "random_url = urls[0]\n",
        "documents = SimpleWebPageReader(html_to_text=True).load_data([random_url])\n",
        "assert len(documents)==1\n",
        "extractor = QuestionsAnsweredExtractor(questions=1)\n",
        "questions = await extractor.aextract(documents)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b280db13",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "url https://inspection.canada.ca/preventive-controls/sampling-procedures/eng/1518033335104/1528203403149\n",
            "What are the steps and considerations involved in the sampling procedures for food safety according to the Canadian Food Inspection Agency?\n"
          ]
        }
      ],
      "source": [
        "print(\"url\", random_url)\n",
        "question = questions[0][\"questions_this_excerpt_can_answer\"].removeprefix(\"Question: \")\n",
        "print(question)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e173a78",
      "metadata": {},
      "source": [
        "#### Checking if querying the index returns the right url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "158034e3",
      "metadata": {},
      "outputs": [],
      "source": [
        "vector_store = PGVectorStore.from_params(\n",
        "    database=new_database,\n",
        "    host=host,\n",
        "    password=password,\n",
        "    port=port,\n",
        "    user=user,\n",
        "    embed_dim=1536,\n",
        ")\n",
        "\n",
        "index = VectorStoreIndex.from_vector_store(vector_store=vector_store)\n",
        "retriever = index.as_retriever(similarity_top_k=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "772f9ea7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "start.............\n",
            "get_agg_embedding_from_queries: 0.20 seconds\n",
            "_build_vector_store_query: 0.00 seconds\n",
            "_vector_store.query: 1.20 seconds\n",
            "_retrieve: 1.39 seconds\n",
            "_handle_recursive_retrieval: 0.00 seconds\n"
          ]
        }
      ],
      "source": [
        "# import time\n",
        "# start_time = time.time()\n",
        "nodes = retriever.retrieve(question)\n",
        "\n",
        "# end_time = time.time()\n",
        "# elapsed_time = end_time - start_time\n",
        "# print(f\"Elapsed time: {elapsed_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "77c4ed49",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'node': {'id_': '4916a845-5358-42e8-93ed-be8b7beddf55', 'embedding': None, 'metadata': {'id': '4916a845-5358-42e8-93ed-be8b7beddf55', 'chunk_id': 'def3245a-e853-46f4-84e4-6b0f32a04983', 'url': 'https://inspection.canada.ca/inspection-and-enforcement/guidance-for-food-inspection-activities/sample-collection/as-required-food-sample-collection/eng/1653062252765/1653062253358', 'title': 'Operational procedure: As required food sample collection - Canadian Food Inspection Agency', 'subtitle': 'On this page;1.0 Purpose;2.0 Authorities', 'tokens_count': 267, 'last_updated': '2022-06-20', 'score': 0.5025328114227888}, 'excluded_embed_metadata_keys': [], 'excluded_llm_metadata_keys': [], 'relationships': {}, 'text': 'On this page 1.0 Purpose 2.0 Authorities 3.0 Reference documents 4.0 Definitions 5.0 Acronyms 6.0 Operational procedure 6.1 Prepare for the inspection 6.2 Conduct the inspection 6.3 Communicate the inspection results 6.4 Conduct the follow-up inspection 7.0 Appendix Annex B: DSDP data entry – CFIA sampled – sample results other than satisfactory (accessible only on the Government of Canada network – RDIMS 14996797)\\n1.0 Purpose The purpose of this document is to provide guidance to Canadian Food Inspection Agency (CFIA) inspection staff on the procedures for as required sample collection under the Food Business Line (FBL). This guidance is written with the assumption that inspection staff have been trained in the Standard Inspection Process (SIP) and the Digital Service Delivery Platform (DSDP). This document is intended to be used in conjunction with Operational guideline: Food sample collection.\\n2.0 Authorities Safe Food for Canadians Act (SFCA) Safe Food for Canadians Regulations (SFCR) Food and Drugs Act (FDA) Food and Drug Regulations (FDR) The inspection powers, control actions and enforcement actions authorized by the above legislation are identified and explained in the Operational guideline – Food regulatory response guidelines.', 'start_char_idx': None, 'end_char_idx': None, 'text_template': '{metadata_str}\\n\\n{content}', 'metadata_template': '{key}: {value}', 'metadata_seperator': '\\n', 'class_name': 'TextNode'}, 'score': 0.8909988999366824, 'class_name': 'NodeWithScore'}\n"
          ]
        }
      ],
      "source": [
        "print(nodes[0].dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "ec2a6918",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Right: https://inspection.canada.ca/preventive-controls/sampling-procedures/eng/1518033335104/1528203403149\n",
            "Wrong:  https://inspection.canada.ca/inspection-and-enforcement/guidance-for-food-inspection-activities/sample-collection/as-required-food-sample-collection/eng/1653062252765/1653062253358\n",
            "Wrong:  https://inspection.canada.ca/food-safety-for-industry/food-safety-rules-for-small-business/eng/1643050798737/1643050800221\n",
            "Wrong:  https://inspection.canada.ca/food-safety-for-industry/information-for-media/eng/1528746083978/1528746084227\n",
            "Wrong:  https://inspection.canada.ca/importing-food-plants-or-animals/food-imports/step-by-step-guide/eng/1523979839705/1523979840095\n",
            "Wrong:  https://inspection.canada.ca/inspection-and-enforcement/guidance-for-food-inspection-activities/sample-collection/eng/1589914459022/1589914459318\n"
          ]
        }
      ],
      "source": [
        "found = False\n",
        "for i, n in enumerate(nodes):\n",
        "    if n.metadata[\"url\"] == random_url:\n",
        "        found = True\n",
        "        print(f\"Position: {i+1}\", n.metadata[\"title\"])\n",
        "\n",
        "if not found:\n",
        "    print(\"Right:\", random_url)\n",
        "    for n in nodes:\n",
        "        print(\"Wrong: \", n.metadata[\"url\"])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
